{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPRFaJxi59w5"
      },
      "source": [
        "# Model BertForSequenceClassification na danych z 4 etykietami"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "tHICsK112_-G"
      },
      "outputs": [],
      "source": [
        "# Importy\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pYCrB84K6P7r"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"reviews_eda1b.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5BGDtsz3G3h",
        "outputId": "59f9850f-e094-4246-8a81-98d3848c8d49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Link', 'Autor', 'Tytuł', 'Data_recenzji', 'Treść_recenzji',\n",
              "       'Średnia_ocen', 'Liczba_ocen', 'Liczba_czytelników', 'Rok_recenzji',\n",
              "       'sentyment'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oNTFiT-P3bPf"
      },
      "outputs": [],
      "source": [
        "# Moje dane\n",
        "texts = df[\"Treść_recenzji\"].tolist()  # Lista tekstów\n",
        "labels = df[\"sentyment\"].tolist()  # Lista etykiet sentymentu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVg2ot4R32GR"
      },
      "outputs": [],
      "source": [
        "texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dzielę na zbiór treningowy, walidacyjny i testowy\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tokenizacja tekstu\n",
        "tokenizer = BertTokenizer.from_pretrained('google-bert/bert-base-multilingual-cased')\n",
        "\n",
        "tokenized_train = tokenizer(train_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "tokenized_val = tokenizer(val_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "tokenized_test = tokenizer(test_texts, padding=True, truncation=True, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Konwersja etykiet do tensorów\n",
        "train_labels = torch.tensor(train_labels)\n",
        "val_labels = torch.tensor(val_labels)\n",
        "test_labels = torch.tensor(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Muszę zrobić TensorDataset\n",
        "train_dataset = TensorDataset(tokenized_train.input_ids, tokenized_train.attention_mask, tokenized_train.token_type_ids, train_labels)\n",
        "val_dataset = TensorDataset(tokenized_val.input_ids, tokenized_val.attention_mask, tokenized_val.token_type_ids, val_labels)\n",
        "test_dataset = TensorDataset(tokenized_test.input_ids, tokenized_test.attention_mask, tokenized_test.token_type_ids, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#jaikes błedy, więc robię  DataLoader\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google-bert/bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Inicjalizuję model\n",
        "model = BertForSequenceClassification.from_pretrained('google-bert/bert-base-multilingual-cased', num_labels=4)\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "# Trenowanie modelu\n",
        "num_epochs = 3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(epoch)\n",
        "    model.train()\n",
        "    for batch in train_dataloader:\n",
        "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'token_type_ids': batch[2], 'labels': batch[3]}\n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ewaluacja modelu\n",
        "model.eval()\n",
        "all_predictions = []\n",
        "all_true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'token_type_ids': batch[2]}\n",
        "        outputs = model(**inputs)\n",
        "        predictions = torch.argmax(outputs.logits, dim=1)\n",
        "        all_predictions.extend(predictions.tolist())\n",
        "        all_true_labels.extend(batch[3].tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U5tde_aGf2-",
        "outputId": "f9f397a6-7b65-4019-f440-2966d1d78ae2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        36\n",
            "           1       0.00      0.00      0.00       184\n",
            "           2       0.63      1.00      0.77       750\n",
            "           3       0.00      0.00      0.00       223\n",
            "\n",
            "    accuracy                           0.63      1193\n",
            "   macro avg       0.16      0.25      0.19      1193\n",
            "weighted avg       0.40      0.63      0.49      1193\n",
            "\n",
            "Accuracy: 0.6286672254819782\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\konta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\konta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\konta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# wyniki\n",
        "print(classification_report(all_true_labels, all_predictions))\n",
        "print(\"Accuracy:\", accuracy_score(all_true_labels, all_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "smote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import torch\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dziele na zbiór treningowy, walidacyjny i testowy\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tokenizacja tekstu\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "tokenized_train = tokenizer(train_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "tokenized_val = tokenizer(val_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "tokenized_test = tokenizer(test_texts, padding=True, truncation=True, return_tensors=\"pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Oversampling SMOTE\n",
        "# były błedy, więc muszę przekształcic dane treningowe do postaci 2D array\n",
        "X_train_smote = torch.cat([tokenized_train.input_ids, tokenized_train.attention_mask, tokenized_train.token_type_ids], dim=1).numpy()\n",
        "smote = SMOTE(random_state=42, sampling_strategy='auto')\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_smote, train_labels.numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dzielę dane z powrotem na tokeny i etykiety\n",
        "tokenized_train_resampled = torch.tensor(X_train_resampled[:, :tokenized_train.input_ids.shape[1]]), \\\n",
        "                            torch.tensor(X_train_resampled[:, tokenized_train.input_ids.shape[1]:2*tokenized_train.input_ids.shape[1]]), \\\n",
        "                            torch.tensor(X_train_resampled[:, 2*tokenized_train.input_ids.shape[1]:]), \\\n",
        "                            torch.tensor(y_train_resampled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tworzę DataLoader dla danych po oversamplingu\n",
        "train_dataloader_resampled = DataLoader(TensorDataset(*tokenized_train_resampled), batch_size=8, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Oversampling SMOTE dla danych walidacyjnych \n",
        "X_val_smote = torch.cat([tokenized_val.input_ids, tokenized_val.attention_mask, tokenized_val.token_type_ids], dim=1).numpy()\n",
        "X_val_resampled, y_val_resampled = smote.fit_resample(X_val_smote, val_labels.numpy())\n",
        "\n",
        "tokenized_val_resampled = torch.tensor(X_val_resampled[:, :tokenized_val.input_ids.shape[1]]), \\\n",
        "                          torch.tensor(X_val_resampled[:, tokenized_val.input_ids.shape[1]:2*tokenized_val.input_ids.shape[1]]), \\\n",
        "                          torch.tensor(X_val_resampled[:, 2*tokenized_val.input_ids.shape[1]:]), \\\n",
        "                          torch.tensor(y_val_resampled)\n",
        "\n",
        "val_dataloader_resampled = DataLoader(TensorDataset(*tokenized_val_resampled), batch_size=8, shuffle=False)\n",
        "\n",
        "# Oversampling SMOTE dla danych testowych \n",
        "X_test_smote = torch.cat([tokenized_test.input_ids, tokenized_test.attention_mask, tokenized_test.token_type_ids], dim=1).numpy()\n",
        "X_test_resampled, y_test_resampled = smote.fit_resample(X_test_smote, test_labels.numpy())\n",
        "\n",
        "tokenized_test_resampled = torch.tensor(X_test_resampled[:, :tokenized_test.input_ids.shape[1]]), \\\n",
        "                           torch.tensor(X_test_resampled[:, tokenized_test.input_ids.shape[1]:2*tokenized_test.input_ids.shape[1]]), \\\n",
        "                           torch.tensor(X_test_resampled[:, 2*tokenized_test.input_ids.shape[1]:]), \\\n",
        "                           torch.tensor(y_test_resampled)\n",
        "\n",
        "test_dataloader_resampled = DataLoader(TensorDataset(*tokenized_test_resampled), batch_size=8, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\konta\\AppData\\Local\\Temp\\ipykernel_22544\\4000818539.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_labels = torch.tensor(train_labels)\n",
            "C:\\Users\\konta\\AppData\\Local\\Temp\\ipykernel_22544\\4000818539.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_labels = torch.tensor(val_labels)\n",
            "C:\\Users\\konta\\AppData\\Local\\Temp\\ipykernel_22544\\4000818539.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_labels = torch.tensor(test_labels)\n"
          ]
        }
      ],
      "source": [
        "# Konwersja etykiet do tensorów\n",
        "train_labels = torch.tensor(train_labels)\n",
        "val_labels = torch.tensor(val_labels)\n",
        "test_labels = torch.tensor(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.optim import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Inicjalizuję modelu\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=4)\n",
        "optimizer = Adam(model.parameters(), lr=5e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "# Trening modelu\n",
        "num_epochs = 3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(epoch)\n",
        "    model.train()\n",
        "    for batch in train_dataloader_resampled:\n",
        "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'token_type_ids': batch[2], 'labels': batch[3]}\n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ewaluacja modelu\n",
        "model.eval()\n",
        "all_predictions = []\n",
        "all_true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_dataloader_resampled:\n",
        "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'token_type_ids': batch[2]}\n",
        "        outputs = model(**inputs)\n",
        "        predictions = torch.argmax(outputs.logits, dim=1)\n",
        "        all_predictions.extend(predictions.tolist())\n",
        "        all_true_labels.extend(batch[3].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      1.00      0.40       300\n",
            "           1       0.00      0.00      0.00       300\n",
            "           2       0.00      0.00      0.00       300\n",
            "           3       0.00      0.00      0.00       300\n",
            "\n",
            "    accuracy                           0.25      1200\n",
            "   macro avg       0.06      0.25      0.10      1200\n",
            "weighted avg       0.06      0.25      0.10      1200\n",
            "\n",
            "Accuracy: 0.25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\konta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\konta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\konta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Wyniki\n",
        "print(classification_report(all_true_labels, all_predictions))\n",
        "print(\"Accuracy:\", accuracy_score(all_true_labels, all_predictions))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
